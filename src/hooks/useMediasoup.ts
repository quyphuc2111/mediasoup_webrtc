import { useState, useCallback, useRef, useEffect } from 'react';
import { MediasoupClient, ConnectionState, MediaKind } from '../lib/mediasoup-client';

interface Peer {
  id: string;
  name: string;
  isTeacher: boolean;
}

// Helper function to check MediaDevices availability
const checkMediaDevicesSupport = () => {
  const nav = typeof navigator !== 'undefined' ? navigator : (window as any).navigator;
  
  if (!nav) {
    return { available: false, error: 'Navigator kh√¥ng t·ªìn t·∫°i' };
  }

  // Try to access mediaDevices - may be undefined in some WebView contexts
  let mediaDevices = nav.mediaDevices;
  
  // If mediaDevices doesn't exist, try to initialize it (for older browsers/WebViews)
  if (!mediaDevices) {
    // Try legacy APIs as fallback
    if (nav.getUserMedia) {
      console.warn('Using legacy getUserMedia API');
    }
    
    // For Tauri WebView, mediaDevices might not be initialized immediately
    // Try to access it via a getter or wait
    try {
      // Check if we're in a secure context (required for mediaDevices)
      if (typeof window !== 'undefined' && (window.location.protocol === 'https:' || window.location.hostname === 'localhost' || window.location.hostname === '127.0.0.1')) {
        // MediaDevices should be available in secure context
        // It might be lazily initialized
        mediaDevices = nav.mediaDevices;
      }
    } catch (e) {
      console.warn('Error checking secure context:', e);
    }

    if (!mediaDevices) {
      return { 
        available: false, 
        error: 'navigator.mediaDevices kh√¥ng t·ªìn t·∫°i. C√≥ th·ªÉ WebView ch∆∞a h·ªó tr·ª£ MediaDevices API ho·∫∑c ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh ƒë√∫ng.',
        userAgent: nav.userAgent,
        isSecureContext: typeof window !== 'undefined' ? (window.location.protocol === 'https:' || window.location.hostname === 'localhost') : false
      };
    }
  }

  const md = mediaDevices;
  
  return {
    available: true,
    hasGetDisplayMedia: typeof md.getDisplayMedia === 'function',
    hasGetUserMedia: typeof md.getUserMedia === 'function',
    methods: Object.keys(md),
    userAgent: nav.userAgent,
    isSecureContext: typeof window !== 'undefined' ? (window.location.protocol === 'https:' || window.location.hostname === 'localhost') : false
  };
};

export function useMediasoup() {
  const [connectionState, setConnectionState] = useState<ConnectionState>('disconnected');
  const [error, setError] = useState<string | null>(null);
  const [peers, setPeers] = useState<Peer[]>([]);
  const [remoteStream, setRemoteStream] = useState<MediaStream | null>(null);
  const [isSharing, setIsSharing] = useState(false);
  const [localStream, setLocalStream] = useState<MediaStream | null>(null);
  const [isMicActive, setIsMicActive] = useState(false);
  const [micStream, setMicStream] = useState<MediaStream | null>(null);
  const micProducerIdRef = useRef<string | null>(null);

  const clientRef = useRef<MediasoupClient | null>(null);

  useEffect(() => {
    // Check MediaDevices availability on mount for debugging
    const checkSupport = () => {
      const support = checkMediaDevicesSupport();
      console.log('[useMediasoup] MediaDevices Support on Mount:', support);
      
      if (support.available && support.hasGetDisplayMedia) {
        console.log('[useMediasoup] ‚úÖ getDisplayMedia is available');
      } else {
        console.warn('[useMediasoup] ‚ö†Ô∏è getDisplayMedia may not be available:', support);
      }
    };

    // Check immediately
    checkSupport();

    // Also check after a short delay (in case WebView needs time to initialize)
    const timeoutId = setTimeout(checkSupport, 500);

    return () => {
      clearTimeout(timeoutId);
      clientRef.current?.disconnect();
    };
  }, []);

  const connect = useCallback(async (
    serverUrl: string,
    roomId: string,
    name: string,
    isTeacher: boolean
  ) => {
    const peerId = crypto.randomUUID();

    const client = new MediasoupClient({
      onConnectionStateChange: setConnectionState,
      onError: setError,
      onPeerJoined: (id, peerName, peerIsTeacher) => {
        setPeers(prev => [...prev, { id, name: peerName, isTeacher: peerIsTeacher }]);
      },
      onPeerLeft: (id, wasTeacher) => {
        setPeers(prev => prev.filter(p => p.id !== id));
        if (wasTeacher) {
          setRemoteStream(null);
        }
      },
      onNewProducer: async (producerId: string, kind: MediaKind) => {
        // Auto-consume new producers (for students)
        if (!client.isTeacher) {
          console.log(`[Student] New producer detected: ${producerId}, kind: ${kind}`);
          console.log(`[Student] Client connection state: ${clientRef.current ? 'exists' : 'null'}`);
          
          // Wait a bit to ensure transport is ready (in case of race condition)
          await new Promise(resolve => setTimeout(resolve, 100));
          
          if (!clientRef.current) {
            console.error(`[Student] ‚ùå Client is null, cannot consume producer ${producerId}`);
            return;
          }
          
          try {
            const consumer = await clientRef.current.consume(producerId);
            if (consumer) {
              console.log(`[Student] ‚úÖ Successfully consumed producer ${producerId}, track:`, consumer.track);
              setRemoteStream(prev => {
                const stream = prev || new MediaStream();
                
                // Remove old track of the same kind to avoid duplicates
                const existingTracks = stream.getTracks().filter(t => t.kind === consumer.track.kind);
                existingTracks.forEach(track => {
                  stream.removeTrack(track);
                  track.stop();
                  console.log(`[Student] Removed old ${track.kind} track`);
                });
                
                // Add new track
                stream.addTrack(consumer.track);
                console.log(`[Student] Stream now has ${stream.getTracks().length} tracks (kind: ${stream.getTracks().map(t => t.kind).join(', ')})`);
                return stream;
              });
            } else {
              console.error(`[Student] ‚ùå Failed to consume producer ${producerId} - consumer is null`);
              setError(`Kh√¥ng th·ªÉ nh·∫≠n ƒë∆∞·ª£c stream t·ª´ producer ${producerId}`);
            }
          } catch (err) {
            console.error(`[Student] ‚ùå Error consuming producer ${producerId}:`, err);
            setError(err instanceof Error ? err.message : `Failed to consume producer ${producerId}`);
          }
        }
      },
      onStreamReady: setRemoteStream,
    });

    clientRef.current = client;

    try {
      await client.connect(serverUrl, roomId, peerId, name, isTeacher);

      // Students: create recv transport and consume existing producers
      if (!isTeacher) {
        try {
          console.log('[Student] Attempting to consume all existing producers...');
          const stream = await client.consumeAll();
          console.log('[Student] ConsumeAll result:', stream, 'tracks:', stream?.getTracks().length);
          
          // Ensure remoteStream is set even if consumeAll returns empty stream
          if (stream && stream.getTracks().length > 0) {
            setRemoteStream(stream);
            console.log('[Student] ‚úÖ Remote stream set with', stream.getTracks().length, 'tracks');
          } else {
            console.log('[Student] No producers yet, waiting for teacher to share...');
          }
        } catch (consumeErr) {
          // Kh√¥ng c√≥ producer n√†o - teacher ch∆∞a share, kh√¥ng ph·∫£i l·ªói
          console.log('[Student] No producers yet or error consuming:', consumeErr);
          setError(consumeErr instanceof Error ? consumeErr.message : 'Failed to consume producers');
        }
      }
    } catch (err) {
      console.error('Connection error:', err);
      setError(err instanceof Error ? err.message : 'Connection failed');
    }
  }, []);

  const stopScreenShare = useCallback(() => {
    setLocalStream(prevStream => {
      if (prevStream) {
        prevStream.getTracks().forEach(track => track.stop());
      }
      return null;
    });
    clientRef.current?.stopProducing();
    setIsSharing(false);
  }, []);

  const startScreenShare = useCallback(async (withAudio: boolean = true) => {
    if (!clientRef.current) return;

    try {
      // Check MediaDevices support and log detailed info for debugging
      const support = checkMediaDevicesSupport();
      console.log('MediaDevices Support Check:', support);
      
      if (!support.available || !support.hasGetDisplayMedia) {
        const errorMsg = support.error || 
          'getDisplayMedia kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng ki·ªÉm tra:\n' +
          '- Tauri ƒëang s·ª≠ d·ª•ng WebView h·ªó tr·ª£ MediaDevices API\n' +
          '- C·∫•u h√¨nh Tauri cho ph√©p truy c·∫≠p MediaDevices\n' +
          '- ·ª®ng d·ª•ng c√≥ quy·ªÅn truy c·∫≠p screen recording (macOS)';
        
        console.error('MediaDevices Debug Info:', {
          support,
          navigatorType: typeof navigator,
          windowNavigator: typeof (window as any).navigator,
          mediaDevices: (typeof navigator !== 'undefined' ? navigator : (window as any).navigator)?.mediaDevices
        });
        
        throw new Error(errorMsg);
      }

      // Get navigator and mediaDevices
      const nav = typeof navigator !== 'undefined' ? navigator : (window as any).navigator;
      const mediaDevices = nav.mediaDevices;

      // Get screen with system audio - T·ªëi ∆∞u cho Windows
      const screenStream = await mediaDevices.getDisplayMedia({
        video: {
          width: { ideal: 1920, max: 1920 }, // 1080p Full HD
          height: { ideal: 1080, max: 1080 }, // 1080p Full HD
          // üëá QUAN TR·ªåNG: Chrome tr√™n Windows 25fps m∆∞·ª£t h∆°n 30fps r·∫•t nhi·ªÅu
          // M·∫Øt ng∆∞·ªùi kh√¥ng ph√¢n bi·ªát r√µ 25 vs 30, nh∆∞ng Windows encoder ·ªïn ƒë·ªãnh h∆°n ·ªü 25fps
          frameRate: { ideal: 25, max: 30 }, // 25fps ideal cho Windows
        },
        audio: withAudio,
      });

      setLocalStream(screenStream);
      await clientRef.current.produceScreen(screenStream);
      setIsSharing(true);

      // Handle stream end (user clicks "Stop sharing")
      const videoTrack = screenStream.getVideoTracks()[0];
      if (videoTrack) {
        videoTrack.onended = () => {
          stopScreenShare();
        };
      }
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to share screen');
    }
  }, [stopScreenShare]);

  const startMicrophone = useCallback(async () => {
    if (!clientRef.current) return;

    try {
      // Check if navigator exists and mediaDevices API is available
      const nav = typeof navigator !== 'undefined' ? navigator : (window as any).navigator;
      if (!nav || !nav.mediaDevices || typeof nav.mediaDevices.getUserMedia !== 'function') {
        throw new Error('Microphone API kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng ƒë·∫£m b·∫£o b·∫°n ƒëang s·ª≠ d·ª•ng phi√™n b·∫£n tr√¨nh duy·ªát/Tauri h·ªó tr·ª£ getUserMedia.');
      }

      const mediaDevices = nav.mediaDevices;

      // Check permission state if available (not all browsers support this)
      try {
        // TypeScript may not recognize 'microphone' as PermissionName, so we use any
        const permissions = (mediaDevices as any).permissions;
        if (permissions && typeof permissions.query === 'function') {
          const permissionStatus = await permissions.query({ name: 'microphone' });
          console.log('[Microphone] Permission status:', permissionStatus.state);
          
          if (permissionStatus.state === 'denied') {
            throw new Error('Quy·ªÅn truy c·∫≠p microphone ƒë√£ b·ªã t·ª´ ch·ªëi. Vui l√≤ng c·∫•p quy·ªÅn trong System Settings > Privacy & Security > Microphone tr√™n macOS.');
          }
        }
      } catch (permErr) {
        // Permission query kh√¥ng kh·∫£ d·ª•ng, ti·∫øp t·ª•c th·ª≠ request
        // (This is normal - not all browsers/WebViews support permission query API)
        console.warn('[Microphone] Could not query permission (this is normal):', permErr);
      }

      // Request microphone access
      console.log('[Microphone] Requesting microphone access...');
      const micStream = await mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          // C√≥ th·ªÉ th·ª≠ constraints ƒë∆°n gi·∫£n h∆°n n·∫øu b·ªã t·ª´ ch·ªëi
          sampleRate: { ideal: 48000 },
          channelCount: { ideal: 1 },
        },
        video: false,
      });

      console.log('[Microphone] ‚úÖ Microphone access granted');
      
      // Store microphone stream
      setMicStream(micStream);
      setIsMicActive(true);
      
      // Produce microphone and track producer ID
      const producerId = await clientRef.current.produceMicrophone(micStream);
      if (producerId) {
        micProducerIdRef.current = producerId;
        console.log('[Microphone] Microphone producer ID:', producerId);
      }
    } catch (err) {
      console.error('[Microphone] ‚ùå Error accessing microphone:', err);
      
      let errorMessage = 'Kh√¥ng th·ªÉ truy c·∫≠p microphone.';
      
      if (err instanceof Error) {
        const errName = err.name || '';
        const errMsg = err.message || '';
        
        // Handle specific error cases
        if (errName === 'NotAllowedError' || errMsg.includes('not allowed') || errMsg.includes('permission denied') || errMsg.includes('denied')) {
          errorMessage = 'Quy·ªÅn truy c·∫≠p microphone b·ªã t·ª´ ch·ªëi. Vui l√≤ng:\n' +
            '1. Ki·ªÉm tra System Settings > Privacy & Security > Microphone\n' +
            '2. ƒê·∫£m b·∫£o ·ª©ng d·ª•ng c√≥ quy·ªÅn truy c·∫≠p microphone\n' +
            '3. Th·ª≠ l·∫°i sau khi c·∫•p quy·ªÅn';
        } else if (errName === 'NotFoundError' || errMsg.includes('not found')) {
          errorMessage = 'Kh√¥ng t√¨m th·∫•y microphone. Vui l√≤ng ki·ªÉm tra thi·∫øt b·ªã microphone ƒë√£ ƒë∆∞·ª£c k·∫øt n·ªëi ch∆∞a.';
        } else if (errName === 'NotReadableError' || errMsg.includes('not readable')) {
          errorMessage = 'Microphone ƒëang ƒë∆∞·ª£c s·ª≠ d·ª•ng b·ªüi ·ª©ng d·ª•ng kh√°c. Vui l√≤ng ƒë√≥ng c√°c ·ª©ng d·ª•ng kh√°c ƒëang s·ª≠ d·ª•ng microphone.';
        } else {
          errorMessage = errMsg || 'Kh√¥ng th·ªÉ truy c·∫≠p microphone.';
        }
      }
      
      setError(errorMessage);
    }
  }, []);

  const stopMicrophone = useCallback(() => {
    // Stop microphone producer in mediasoup client first
    if (clientRef.current && micProducerIdRef.current) {
      clientRef.current.stopProducer(micProducerIdRef.current);
      micProducerIdRef.current = null;
    }
    
    if (micStream) {
      // Stop all audio tracks from microphone stream
      micStream.getAudioTracks().forEach(track => {
        track.stop();
        console.log('[Microphone] Stopped audio track');
      });
      setMicStream(null);
    }
    
    setIsMicActive(false);
    
    console.log('[Microphone] ‚úÖ Microphone stopped');
  }, [micStream]);

  const disconnect = useCallback(() => {
    stopScreenShare();
    stopMicrophone();
    clientRef.current?.disconnect();
    clientRef.current = null;
    setConnectionState('disconnected');
    setPeers([]);
    setRemoteStream(null);
    setIsMicActive(false);
    setMicStream(null);
  }, [stopScreenShare, stopMicrophone]);

  return {
    connectionState,
    error,
    peers,
    remoteStream,
    localStream,
    isSharing,
    isMicActive,
    connect,
    disconnect,
    startScreenShare,
    startMicrophone,
    stopScreenShare,
    stopMicrophone,
  };
}
